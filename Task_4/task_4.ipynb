{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebc753d-666e-4a7b-b944-3ce9479bd867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import SamModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b96b9ae5-f866-4d48-804d-f9e20c9d5881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pretrained SAM Model from Hugging Face\n",
    "sam_model = SamModel.from_pretrained(\"facebook/sam-vit-huge\")\n",
    "\n",
    "\n",
    "# Unfreeze the last 4 layers for fine-tuning\n",
    "for layer in sam_model.vision_encoder.layers[-4:]:  \n",
    "    layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b15be0b-bcf3-4df3-9062-fbf57a2e0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Input Shape (Multispectral Image)\n",
    "INPUT_SHAPE = (128, 128, 12)\n",
    "inputs = layers.Input(shape=INPUT_SHAPE)\n",
    "\n",
    "# Use SAM's encoder features\n",
    "x = layers.Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = layers.BatchNormalization()(x)  # BatchNorm instead of Dropout\n",
    "x = layers.Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "# Custom Segmentation Head\n",
    "x = layers.Conv2DTranspose(128, (3, 3), strides=1, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(64, (3, 3), strides=1, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(1, (1, 1), activation=\"sigmoid\")(x)  # Keep final output at (128, 128, 1)\n",
    "\n",
    "# Build Model\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31093e88-f123-4632-bb81-dc358baa403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  # Lower LR for fine-tuning\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.MeanIoU(num_classes=2),\n",
    "        tf.keras.metrics.BinaryAccuracy()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd3ac25b-7006-4256-9b77-e9982ae350fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">27,904</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_transpose (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_transpose_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m27,904\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m590,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_transpose (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m295,040\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_transpose_1 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m73,792\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">989,697</span> (3.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m989,697\u001b[0m (3.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">988,289</span> (3.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m988,289\u001b[0m (3.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "700e291e-7065-441b-a811-a9f31a73a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Load TIFF Images (12-band) with Min-Max Normalization\n",
    "def load_image(image_path):\n",
    "    with rasterio.open(image_path) as src:\n",
    "        image = src.read().astype(np.float32)  # Shape: (12, 128, 128)\n",
    "        image = np.transpose(image, (1, 2, 0))  # Convert to (128, 128, 12)\n",
    "\n",
    "    # Min-max normalization per channel\n",
    "    min_val = np.min(image, axis=(0, 1), keepdims=True)\n",
    "    max_val = np.max(image, axis=(0, 1), keepdims=True)\n",
    "    normalized_image = (image - min_val) / (max_val - min_val + 1e-7)\n",
    "    \n",
    "    return normalized_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "678fdff9-ddb4-4aa8-b687-d8e3caf75799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Load Labels (Binary Masks)\n",
    "def load_label(label_path):\n",
    "    label = tf.keras.preprocessing.image.load_img(label_path, color_mode=\"grayscale\")\n",
    "    label = np.array(label, dtype=np.uint8)  # Convert to numpy array\n",
    "    label = (label > 0).astype(np.int32)  # Ensure binary format\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b070475-83a9-4c24-a0ba-2db717d4eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to images and labels\n",
    "data_dir = r\"C:\\Users\\Eman\\Downloads\\images-20250217T060743Z-001\\images\"\n",
    "labels_dir = r\"C:\\Users\\Eman\\Downloads\\labels-20250217T060744Z-001\\labels\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a6b7fd-f091-4ba2-af2d-3f01ba76aa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eman\\anaconda3\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Get sorted lists of image and label file paths\n",
    "image_paths = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".tif\")])\n",
    "label_paths = sorted([os.path.join(labels_dir, f) for f in os.listdir(labels_dir) if f.endswith(\".png\")])\n",
    "\n",
    "# Load Data into NumPy Arrays\n",
    "X = np.array([load_image(p) for p in image_paths])\n",
    "Y = np.array([load_label(p) for p in label_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e24b8886-691b-49cb-8d65-1a7e696407cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split Data (70% Training, 15% Validation, 15% Testing)\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcd1b96c-a6d3-46f6-ad90-3d72ddc98e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 9s/step - binary_accuracy: 0.7174 - loss: 0.5570 - mean_io_u: 0.3604 - val_binary_accuracy: 0.8283 - val_loss: 0.6431 - val_mean_io_u: 0.3703\n",
      "Epoch 2/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 9s/step - binary_accuracy: 0.8740 - loss: 0.3459 - mean_io_u: 0.3620 - val_binary_accuracy: 0.8205 - val_loss: 0.5879 - val_mean_io_u: 0.3703\n",
      "Epoch 3/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 9s/step - binary_accuracy: 0.8981 - loss: 0.2876 - mean_io_u: 0.3695 - val_binary_accuracy: 0.8114 - val_loss: 0.5500 - val_mean_io_u: 0.3703\n",
      "Epoch 4/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 9s/step - binary_accuracy: 0.8886 - loss: 0.2942 - mean_io_u: 0.3697 - val_binary_accuracy: 0.7927 - val_loss: 0.5334 - val_mean_io_u: 0.3703\n",
      "Epoch 5/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 9s/step - binary_accuracy: 0.8909 - loss: 0.2899 - mean_io_u: 0.3870 - val_binary_accuracy: 0.7465 - val_loss: 0.5141 - val_mean_io_u: 0.3703\n",
      "Epoch 6/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 9s/step - binary_accuracy: 0.9014 - loss: 0.2705 - mean_io_u: 0.4013 - val_binary_accuracy: 0.7407 - val_loss: 0.5088 - val_mean_io_u: 0.3703\n",
      "Epoch 7/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 9s/step - binary_accuracy: 0.8955 - loss: 0.2939 - mean_io_u: 0.4272 - val_binary_accuracy: 0.7407 - val_loss: 0.5091 - val_mean_io_u: 0.3703\n",
      "Epoch 8/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 9s/step - binary_accuracy: 0.9036 - loss: 0.2612 - mean_io_u: 0.3779 - val_binary_accuracy: 0.7407 - val_loss: 0.5005 - val_mean_io_u: 0.3703\n",
      "Epoch 9/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9s/step - binary_accuracy: 0.9019 - loss: 0.2469 - mean_io_u: 0.3615 - val_binary_accuracy: 0.7407 - val_loss: 0.4940 - val_mean_io_u: 0.3703\n",
      "Epoch 10/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9s/step - binary_accuracy: 0.8865 - loss: 0.2974 - mean_io_u: 0.3629 - val_binary_accuracy: 0.7407 - val_loss: 0.4891 - val_mean_io_u: 0.3703\n",
      "Epoch 11/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9s/step - binary_accuracy: 0.9182 - loss: 0.2210 - mean_io_u: 0.3807 - val_binary_accuracy: 0.7407 - val_loss: 0.4783 - val_mean_io_u: 0.3703\n",
      "Epoch 12/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9s/step - binary_accuracy: 0.9143 - loss: 0.2341 - mean_io_u: 0.3976 - val_binary_accuracy: 0.7407 - val_loss: 0.4737 - val_mean_io_u: 0.3703\n",
      "Epoch 13/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9s/step - binary_accuracy: 0.9174 - loss: 0.2363 - mean_io_u: 0.4119 - val_binary_accuracy: 0.7407 - val_loss: 0.4719 - val_mean_io_u: 0.3703\n",
      "Epoch 14/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 9s/step - binary_accuracy: 0.9160 - loss: 0.2211 - mean_io_u: 0.3916 - val_binary_accuracy: 0.7496 - val_loss: 0.4561 - val_mean_io_u: 0.3703\n",
      "Epoch 15/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9s/step - binary_accuracy: 0.9111 - loss: 0.2393 - mean_io_u: 0.4144 - val_binary_accuracy: 0.7652 - val_loss: 0.4566 - val_mean_io_u: 0.3703\n",
      "Epoch 16/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 9s/step - binary_accuracy: 0.9049 - loss: 0.2619 - mean_io_u: 0.4225 - val_binary_accuracy: 0.7879 - val_loss: 0.4535 - val_mean_io_u: 0.3703\n",
      "Epoch 17/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 9s/step - binary_accuracy: 0.9135 - loss: 0.2248 - mean_io_u: 0.3952 - val_binary_accuracy: 0.8137 - val_loss: 0.4441 - val_mean_io_u: 0.3703\n",
      "Epoch 18/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 9s/step - binary_accuracy: 0.9142 - loss: 0.2286 - mean_io_u: 0.4000 - val_binary_accuracy: 0.8145 - val_loss: 0.4386 - val_mean_io_u: 0.3703\n",
      "Epoch 19/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9s/step - binary_accuracy: 0.9016 - loss: 0.2513 - mean_io_u: 0.3885 - val_binary_accuracy: 0.8102 - val_loss: 0.4368 - val_mean_io_u: 0.3703\n",
      "Epoch 20/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 9s/step - binary_accuracy: 0.9025 - loss: 0.2561 - mean_io_u: 0.3993 - val_binary_accuracy: 0.8203 - val_loss: 0.4272 - val_mean_io_u: 0.3703\n",
      "Epoch 21/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 9s/step - binary_accuracy: 0.9178 - loss: 0.2339 - mean_io_u: 0.4255 - val_binary_accuracy: 0.8211 - val_loss: 0.4166 - val_mean_io_u: 0.3703\n",
      "Epoch 22/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 9s/step - binary_accuracy: 0.9099 - loss: 0.2346 - mean_io_u: 0.4320 - val_binary_accuracy: 0.8204 - val_loss: 0.4292 - val_mean_io_u: 0.3703\n",
      "Epoch 23/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 9s/step - binary_accuracy: 0.9203 - loss: 0.2180 - mean_io_u: 0.4111 - val_binary_accuracy: 0.8204 - val_loss: 0.4249 - val_mean_io_u: 0.3703\n",
      "Epoch 24/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 9s/step - binary_accuracy: 0.9031 - loss: 0.2454 - mean_io_u: 0.3785 - val_binary_accuracy: 0.8233 - val_loss: 0.4286 - val_mean_io_u: 0.3703\n",
      "Epoch 25/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 9s/step - binary_accuracy: 0.9176 - loss: 0.2145 - mean_io_u: 0.4129 - val_binary_accuracy: 0.8274 - val_loss: 0.3996 - val_mean_io_u: 0.3703\n",
      "Epoch 26/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 9s/step - binary_accuracy: 0.9173 - loss: 0.2171 - mean_io_u: 0.4521 - val_binary_accuracy: 0.8257 - val_loss: 0.4077 - val_mean_io_u: 0.3703\n",
      "Epoch 27/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 9s/step - binary_accuracy: 0.9076 - loss: 0.2551 - mean_io_u: 0.4027 - val_binary_accuracy: 0.8275 - val_loss: 0.4198 - val_mean_io_u: 0.3703\n",
      "Epoch 28/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 9s/step - binary_accuracy: 0.9202 - loss: 0.2097 - mean_io_u: 0.4327 - val_binary_accuracy: 0.8356 - val_loss: 0.3529 - val_mean_io_u: 0.3703\n",
      "Epoch 29/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9s/step - binary_accuracy: 0.9135 - loss: 0.2242 - mean_io_u: 0.4336 - val_binary_accuracy: 0.8399 - val_loss: 0.3465 - val_mean_io_u: 0.3703\n",
      "Epoch 30/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9s/step - binary_accuracy: 0.9154 - loss: 0.2200 - mean_io_u: 0.4258 - val_binary_accuracy: 0.8373 - val_loss: 0.3529 - val_mean_io_u: 0.3703\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    batch_size=16,\n",
    "    epochs=30,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "852e984e-24d3-4459-930e-26e3e2691be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.4576, Val_Loss=0.6431, IoU=0.3631, Val_IoU=0.3703, Acc=0.7904, Val_Acc=0.8283\n",
      "Epoch 2: Loss=0.3304, Val_Loss=0.5879, IoU=0.3643, Val_IoU=0.3703, Acc=0.8784, Val_Acc=0.8205\n",
      "Epoch 3: Loss=0.2867, Val_Loss=0.5500, IoU=0.3631, Val_IoU=0.3703, Acc=0.8979, Val_Acc=0.8114\n",
      "Epoch 4: Loss=0.2916, Val_Loss=0.5334, IoU=0.3678, Val_IoU=0.3703, Acc=0.8892, Val_Acc=0.7927\n",
      "Epoch 5: Loss=0.2866, Val_Loss=0.5141, IoU=0.3945, Val_IoU=0.3703, Acc=0.8935, Val_Acc=0.7465\n",
      "Epoch 6: Loss=0.2658, Val_Loss=0.5088, IoU=0.3873, Val_IoU=0.3703, Acc=0.9040, Val_Acc=0.7407\n",
      "Epoch 7: Loss=0.2780, Val_Loss=0.5091, IoU=0.3917, Val_IoU=0.3703, Acc=0.8987, Val_Acc=0.7407\n",
      "Epoch 8: Loss=0.2578, Val_Loss=0.5005, IoU=0.3794, Val_IoU=0.3703, Acc=0.9038, Val_Acc=0.7407\n",
      "Epoch 9: Loss=0.2474, Val_Loss=0.4940, IoU=0.3876, Val_IoU=0.3703, Acc=0.9047, Val_Acc=0.7407\n",
      "Epoch 10: Loss=0.2600, Val_Loss=0.4891, IoU=0.3906, Val_IoU=0.3703, Acc=0.9048, Val_Acc=0.7407\n",
      "Epoch 11: Loss=0.2387, Val_Loss=0.4783, IoU=0.3846, Val_IoU=0.3703, Acc=0.9119, Val_Acc=0.7407\n",
      "Epoch 12: Loss=0.2344, Val_Loss=0.4737, IoU=0.3896, Val_IoU=0.3703, Acc=0.9125, Val_Acc=0.7407\n",
      "Epoch 13: Loss=0.2481, Val_Loss=0.4719, IoU=0.3966, Val_IoU=0.3703, Acc=0.9085, Val_Acc=0.7407\n",
      "Epoch 14: Loss=0.2350, Val_Loss=0.4561, IoU=0.3956, Val_IoU=0.3703, Acc=0.9101, Val_Acc=0.7496\n",
      "Epoch 15: Loss=0.2345, Val_Loss=0.4566, IoU=0.3994, Val_IoU=0.3703, Acc=0.9100, Val_Acc=0.7652\n",
      "Epoch 16: Loss=0.2531, Val_Loss=0.4535, IoU=0.4013, Val_IoU=0.3703, Acc=0.9077, Val_Acc=0.7879\n",
      "Epoch 17: Loss=0.2491, Val_Loss=0.4441, IoU=0.4034, Val_IoU=0.3703, Acc=0.9033, Val_Acc=0.8137\n",
      "Epoch 18: Loss=0.2390, Val_Loss=0.4386, IoU=0.4036, Val_IoU=0.3703, Acc=0.9114, Val_Acc=0.8145\n",
      "Epoch 19: Loss=0.2363, Val_Loss=0.4368, IoU=0.4030, Val_IoU=0.3703, Acc=0.9113, Val_Acc=0.8102\n",
      "Epoch 20: Loss=0.2419, Val_Loss=0.4272, IoU=0.4085, Val_IoU=0.3703, Acc=0.9103, Val_Acc=0.8203\n",
      "Epoch 21: Loss=0.2288, Val_Loss=0.4166, IoU=0.4082, Val_IoU=0.3703, Acc=0.9170, Val_Acc=0.8211\n",
      "Epoch 22: Loss=0.2314, Val_Loss=0.4292, IoU=0.4194, Val_IoU=0.3703, Acc=0.9130, Val_Acc=0.8204\n",
      "Epoch 23: Loss=0.2137, Val_Loss=0.4249, IoU=0.4049, Val_IoU=0.3703, Acc=0.9178, Val_Acc=0.8204\n",
      "Epoch 24: Loss=0.2319, Val_Loss=0.4286, IoU=0.4092, Val_IoU=0.3703, Acc=0.9134, Val_Acc=0.8233\n",
      "Epoch 25: Loss=0.2182, Val_Loss=0.3996, IoU=0.4286, Val_IoU=0.3703, Acc=0.9174, Val_Acc=0.8274\n",
      "Epoch 26: Loss=0.2163, Val_Loss=0.4077, IoU=0.4290, Val_IoU=0.3703, Acc=0.9184, Val_Acc=0.8257\n",
      "Epoch 27: Loss=0.2264, Val_Loss=0.4198, IoU=0.4039, Val_IoU=0.3703, Acc=0.9157, Val_Acc=0.8275\n",
      "Epoch 28: Loss=0.2217, Val_Loss=0.3529, IoU=0.4256, Val_IoU=0.3703, Acc=0.9153, Val_Acc=0.8356\n",
      "Epoch 29: Loss=0.2358, Val_Loss=0.3465, IoU=0.4237, Val_IoU=0.3703, Acc=0.9127, Val_Acc=0.8399\n",
      "Epoch 30: Loss=0.2055, Val_Loss=0.3529, IoU=0.4245, Val_IoU=0.3703, Acc=0.9211, Val_Acc=0.8373\n"
     ]
    }
   ],
   "source": [
    "# Print Training History\n",
    "for epoch, (loss, val_loss, iou, val_iou, acc, val_acc) in enumerate(zip(\n",
    "    history.history[\"loss\"], history.history[\"val_loss\"], \n",
    "    history.history[\"mean_io_u\"], history.history[\"val_mean_io_u\"],\n",
    "    history.history[\"binary_accuracy\"], history.history[\"val_binary_accuracy\"]\n",
    ")):\n",
    "    print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Val_Loss={val_loss:.4f}, IoU={iou:.4f}, Val_IoU={val_iou:.4f}, Acc={acc:.4f}, Val_Acc={val_acc:.4f}\")\n",
    "\n",
    "# Save Model\n",
    "model.save(\"fine_tuned_sam_water_segmentation.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d935bb59-2dd0-4726-8642-112b330282a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - binary_accuracy: 0.8861 - loss: 0.2808 - mean_io_u: 0.4043\n",
      "Test Loss: 0.2817\n",
      "Test IoU: 0.4028\n",
      "Test Accuracy: 0.8855\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate Model on Test Set\n",
    "test_loss, test_iou, test_accuracy = model.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# Print Test Results\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test IoU: {test_iou:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54dfe91-cb74-4bfc-9941-9298419890ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
